# 4. Sorting

## 1. Insertion Sort

### Sorting 
Sorting is used all the time. There's a ton of different sorting algorithm all with their own trade-offs. It's ususally applied to arrays but we can also apply to other data structures including linked lists and others. Supposed we want to sort them such that they're in ascending order. We're gonna achieve this with the insertion sort algorithm.

### Insertion Sort 
The main idea is to break the problem into sub problems again. So if we want to sort the entire array, the first thing would be to have the first portion of the array meaning just the first element have this sorted. The first value is sorted by default. I mean how could this be not sorted if it's just one value. So we consider any array of one value to be sorted. The next thing to do, the next sub problem would be to sort the first two values. And then have the 3, 4 values sorted and keep doing that until we have the entire array sorted. 

So thinking of this way in terms of sub problems makes the algorithm a lot more simple. Now since we're doing it with sub problems, technically if we wanted to we actually could solve this using recursion which is a technique we just learned. But it's not really useful in this case. 

We can do this without recursion aka we can do this iteratively. We can have an iterative solution which is using Loops. Now the idea is we're gonna loop through the array but we're gonna start at the second element because we know that this subarray is aleady sorted. So starting here, assuming that every value before this position meaning this subarray is already sorted order. Our goal now is to have this array be sorted. So our goal really is where to put this value. In this case we don't have a lot choices. The logical thing to do is to compare this value to the only other value in our array. If this is larger, then it should stay where it is. If it's smaller, it should be swap with the value over here. Since this is larger, it can stay here. 

Let's see what the algorithm does. This is why it's called insertion sort because we'er taking one value and inserting it into a sorted array.

sudo code:
```
for(i from 1 to arr.length){
  j = i-1
  while(j>=0 and arr[j] > arr[j+1]){
    tmp = arr[j+1]
    arr[j+1] = arr[j]
    arr[j] tmp
    j -= 1
  }
}
```

>With sorting there's also this notion of stable verse unstable sorting. When we have an array [7,3,7] it will be always sorted [3,7,7]. The difference between stable and unstable algorithm is this. The thing to notice here is that for seven it will appear twice in the array. So first seevn could have gone here and second seven would have gone here. Or they could have been in reverse. Both of those are valid sorting order. But a stable sorting algorithm will preserve the original order when there's a tie.

Do you think Insertion sort is stable? It's gonna stay where it is. So therefore we would achieve this output where the relative order in case of a tie would be preserved. Theses two would stay in the order they were in originally. 

>Time Complexity   
Let's say we were running insertion sort on a list that's already sorted. We compare two values but the execution is just iterating through the list which is big of n time complexity. The inner loop is never going to execute. So in this case (best case) time complexity is O(n). Big O means worst case but it's common to talk about it this way. In this case the best time complexity which would occur when the input is already sorted is going to be linear time complexity. If the input is reversed, it will be worst case, and the time complexity here is N squared time complexity O(n^2). Actually it's 1/2n^2 but we can ignore co-efficients in big O notation. 
